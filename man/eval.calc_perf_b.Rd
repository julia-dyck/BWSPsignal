% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/eval.calc_perf_b.R
\name{eval.calc_perf_b}
\alias{eval.calc_perf_b}
\title{Calculate performance metrics for BWSP Test Configurations}
\usage{
eval.calc_perf_b(pc_list)
}
\arguments{
\item{pc_list}{A list with simulation parameters, test configurations, and file paths
(see \code{\link{sim.setup_simpars}}).}
}
\value{
A data frame with one row per ADR-positive scenario and BWSP test configuration,
including AUC and related performance values.
}
\description{
Computes the area under the ROC curve (AUC) as well as false positive, true positive,
false negative and true negative rates for all BWSP test configurations defined in \code{pc_list$test}
across simulated scenarios.
}
\details{
The function performs BWSP tests for all specified combinations of
posterior CI types, credibility levels, and sensitivity options. AUC is
calculated using the \code{ROCR} package, comparing ADR-positive with control scenarios.
Scenarios with incomplete simulation repetitions return \code{NA} for performance metrics.
}
\references{
\insertAllCited{}
}
\seealso{
\code{\link{bwsp_test}}, \code{\link{eval.rank_auc}}
}
